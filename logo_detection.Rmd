---
title: "logo detection using R"
output:
  pdf_document: default
  html_notebook: default
---

# Introduction
Companies which are most popular among people they have there own copyrights logo. People uses branded things so if someone knows which type of brands people like most ot particular person use so we can know from this exercise. Here, we are detecting logos from images.

Steps are follows for this exercise
1) Import datasets for train and test model
2) Apply model and check accuracy of model
3) Augmented Datasets
4) test model

## Import datasets for train and test model
Here, we are using flickr datasets, create seprate directory for train and test datasets and generate batches of data from images on test and train datasets
```{r,warning=FALSE}
setwd("C:/Users/admin/Desktop/Data Analytics/logo_detection/New_data/")
options(stringsAsFactors = F)
df <- read.csv("flickr_logos_27_dataset_query_set_annotation.txt", sep="\t")
require(keras)

### Xception Transfer-learning example
img_width <- 75
img_height <- 75
batch_size <- 8

train_directory <- "flickrData/train"
test_directory <- "flickrData/test"
```
```{r}

train_generator <- flow_images_from_directory(train_directory, generator = image_data_generator(),
                                              target_size = c(img_width, img_height), color_mode = "rgb",
                                              class_mode = "categorical", batch_size = batch_size, shuffle = TRUE,
                                              seed = 123)

validation_generator <- flow_images_from_directory(test_directory, generator = image_data_generator(),                                                   target_size = c(img_width, img_height), color_mode = "rgb", classes = NULL, class_mode = "categorical", batch_size = batch_size, shuffle = TRUE, seed = 123)


train_samples = 498
validation_samples = 177
```

for data augmentations we need to define some parameters and apply on images and transfer them into matrix
```{r}
datagen <- image_data_generator(
  rotation_range = 20,
  width_shift_range = 0.2,
  height_shift_range = 0.2,
  horizontal_flip = TRUE
)

train_augmented_generator <-  flow_images_from_directory(test_directory, generator = datagen,
                                                         target_size = c(img_width, img_height), color_mode = "rgb", classes = NULL, class_mode = "categorical", batch_size = batch_size, shuffle = TRUE,  seed = 123)

```

## Apply model 
Our dataset is ready for apply model on it. In keras library there is pretrained model called xception v1 model. from this model first we prepare basemodel which will train our dataset.
```{r}
base_model <- application_xception(weights = 'imagenet', include_top = FALSE, input_shape = c(img_width, img_height, 3))



predictions <- base_model$output %>% 
  layer_global_average_pooling_2d(trainable = T) %>% 
  layer_dense(64, trainable = T) %>%
  layer_activation("relu", trainable = T) %>%
  layer_dropout(0.4, trainable = T) %>%
  layer_dense(27, trainable=T) %>%    ## important to adapt to fit the 27 classes in the dataset!
  layer_activation("softmax", trainable=T)
```
Our basemodel is ready for trian our original data. so now we need to train apply basemodel on our train datasets.

```{r}
model <- keras_model(inputs = base_model$input, outputs = predictions)
#################
for (layer in base_model$layers)
  layer$trainable <- FALSE

summary(model)
###################
model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(lr = 0.0025, decay = 1e-5),
  metrics = "accuracy"
)
```
Our model is trained now we need to validate our dataset or apply train model on test datasets so we know the accuracy of our model.
```{r,include=FALSE}
hist <- model %>% fit_generator(
  train_generator,
  steps_per_epoch = as.integer(train_samples/batch_size), 
  epochs = 150, 
  validation_data = validation_generator,
  validation_steps = as.integer(validation_samples/batch_size),
  verbose=2
)
```

```{r}
evaluate_generator(model,validation_generator, validation_samples)
```

## Augmented Datasets
Now for Increase our accuracy we change some parameters of images and try to increase identify accuracy.
```{r,include=FALSE}
hist_aug <- model %>% fit_generator(
  train_augmented_generator,
  steps_per_epoch = as.integer(train_samples/batch_size), 
  epochs = 75, 
  validation_data = validation_generator,
  validation_steps = as.integer(validation_samples/batch_size),
  verbose=2
)
```

```{r}
evaluate_generator(model,validation_generator, validation_samples)
```
Now we can see our model accuracy increase 55% to 82%. Our model perform good.

## Test our model
Our model is ready for new data. So now we should test our model. Inserting logo image into model as test and out model will recognise and give us output
```{r,fig.height=2,fig.width=2}
library(EBImage)
x <- readImage("logo1.png")
display(x)
```

```{r}
img <- image_load("apple.jpg", target_size = c(75,75))
x <- image_to_array(img)
dim(x) <- c(1, dim(x)) 
prediction <- model %>% predict(x)

colnames(prediction) <- unique(df[,2])[1:27]
prediction[,which.max(prediction)]
```

Now here we can see. Our model is working perfectly still we get 79% accuracy after augmenting our model still we need to improve our model accuracy by changing image parameters. 
